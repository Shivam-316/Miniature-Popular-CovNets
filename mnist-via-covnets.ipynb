{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"> Lets read train and test data\n\n* Divided train and test features by **255.0** to normalize it to range **(-1,1)** , generally neural networks perform better in a nomalized range (eg. **MaxMinScaler**) than scaled range (eg. **StandardScaler**)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nX=train.drop('label',axis=1)/255.0\ntestX=test/255.0\ny=train.label","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Splited the train data into train, validation and test (used for evaluation) , **Never touch test data unless predicting**. "},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ntf.random.set_seed(42)\nk=keras.backend\nk.clear_session()\nfrom sklearn.model_selection import train_test_split\nXtrain,Xval,ytrain,yval=train_test_split(X,y,test_size=0.3,random_state=42)\nXtrain,Xtest,ytrain,ytest=train_test_split(Xtrain,ytrain,test_size=0.1,random_state=42)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now my cnn networks are 2D so they accept 4-dim input so we must reshape our input\n\n> But why this shape only, cause the first dimention is no. of **instances/batch_size** so i am using shape[0] , then the images in mnist dataset are **28x28** images flattened so lets un-flatten them, duhhh , and last is no. of **channels** which is 1 as our images are **b/w** not rgb"},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain,Xval,Xtest=tf.Variable(Xtrain),tf.Variable(Xval),tf.Variable(Xtest)\nXtrainpp=tf.reshape(Xtrain,[Xtrain.shape[0],28,28,1])\nXvalpp=tf.reshape(Xval,[Xval.shape[0],28,28,1])\nXtestpp=tf.reshape(Xtest,[Xtest.shape[0],28,28,1])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX=tf.reshape(testX,[testX.shape[0],28,28,1])","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_callbacks = [\n    keras.callbacks.EarlyStopping(patience=5),\n    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n                              patience=3, min_lr=0.0001),\n]","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple CNN (Type-> VGG)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\n\nDefault2D=partial(keras.layers.Conv2D,kernel_size=3,activation='relu',padding='SAME')\nMaxPool2D=partial(keras.layers.MaxPool2D,pool_size=2)\nmodel_vgg=keras.models.Sequential([\n    Default2D(filters=32,kernel_size=5,input_shape=[28,28,1]),\n    MaxPool2D(),\n    Default2D(filters=64),\n    MaxPool2D(),\n    Default2D(filters=128),\n    MaxPool2D(),\n    Default2D(filters=256,kernel_size=2),\n    MaxPool2D(),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(50,activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(25,activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(10,activation='softmax')\n])","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_vgg.summary()","execution_count":37,"outputs":[{"output_type":"stream","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_42 (Conv2D)           (None, 28, 28, 32)        832       \n_________________________________________________________________\nmax_pooling2d_14 (MaxPooling (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_43 (Conv2D)           (None, 14, 14, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_15 (MaxPooling (None, 7, 7, 64)          0         \n_________________________________________________________________\nconv2d_44 (Conv2D)           (None, 7, 7, 128)         73856     \n_________________________________________________________________\nmax_pooling2d_16 (MaxPooling (None, 3, 3, 128)         0         \n_________________________________________________________________\nconv2d_45 (Conv2D)           (None, 3, 3, 256)         131328    \n_________________________________________________________________\nmax_pooling2d_17 (MaxPooling (None, 1, 1, 256)         0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 256)               0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 50)                12850     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 25)                1275      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 25)                0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 10)                260       \n=================================================================\nTotal params: 238,897\nTrainable params: 238,897\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_vgg.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='nadam')\nhistory_vgg=model_vgg.fit(Xtrainpp,ytrain,epochs=20,validation_data=(Xvalpp,yval),callbacks=my_callbacks)","execution_count":38,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n827/827 [==============================] - 5s 7ms/step - loss: 0.4453 - accuracy: 0.8590 - val_loss: 0.1256 - val_accuracy: 0.9663\nEpoch 2/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.1142 - accuracy: 0.9711 - val_loss: 0.0618 - val_accuracy: 0.9840\nEpoch 3/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0785 - accuracy: 0.9803 - val_loss: 0.0498 - val_accuracy: 0.9872\nEpoch 4/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0597 - accuracy: 0.9854 - val_loss: 0.0554 - val_accuracy: 0.9875\nEpoch 5/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0499 - accuracy: 0.9878 - val_loss: 0.0703 - val_accuracy: 0.9859\nEpoch 6/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0441 - accuracy: 0.9891 - val_loss: 0.0554 - val_accuracy: 0.9860\nEpoch 7/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 0.0464 - val_accuracy: 0.9905\nEpoch 8/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0198 - accuracy: 0.9953 - val_loss: 0.0437 - val_accuracy: 0.9909\nEpoch 9/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.0482 - val_accuracy: 0.9901\nEpoch 10/20\n827/827 [==============================] - 6s 7ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0486 - val_accuracy: 0.9907\nEpoch 11/20\n827/827 [==============================] - 5s 7ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.0496 - val_accuracy: 0.9905\nEpoch 12/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0488 - val_accuracy: 0.9924\nEpoch 13/20\n827/827 [==============================] - 5s 6ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0578 - val_accuracy: 0.9923\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_vgg.evaluate(Xtestpp,ytest)","execution_count":39,"outputs":[{"output_type":"stream","text":"92/92 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9922\n","name":"stdout"},{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"[0.07627163082361221, 0.99217689037323]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_vgg.save('mnist_cnn_vgg_992_007.h5') #99.2% accu and 0.07 % loss","execution_count":40,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inseption CNN (Type-> GoogleNet)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Inseption2D(keras.layers.Layer):\n    def __init__(self,f11,f311,f333,f511,f555,fMP11,**kwargs):\n        super().__init__(**kwargs)\n        self.f11=f11\n        self.f311=f311\n        self.f333=f333\n        self.f511=f511\n        self.f555=f555\n        self.fMP11=fMP11\n        \n        self.Conv1x1=keras.layers.Conv2D(filters=self.f11,kernel_size=1,activation='relu',padding='same')\n    \n        self.Conv3SL1x1=keras.layers.Conv2D(filters=self.f311,kernel_size=1,activation='relu',padding='same')\n        self.Conv3SL3x3=keras.layers.Conv2D(filters=self.f333,kernel_size=3,activation='relu',padding='same')\n        \n        self.Conv5SL1x1=keras.layers.Conv2D(filters=self.f511,kernel_size=1,activation='relu',padding='same')\n        self.Conv5SL5x5=keras.layers.Conv2D(filters=self.f555,kernel_size=5,activation='relu',padding='same')\n        \n        self.MaxPool=keras.layers.MaxPooling2D(pool_size=3,strides=1,padding='same')\n        self.ConvMP1x1=keras.layers.Conv2D(filters=self.fMP11,kernel_size=1,activation='relu',padding='same')\n        \n    def call(self,inputs):\n        #Input via 1x1\n        out11=self.Conv1x1(inputs)\n        \n        #Input via Smart Layer (1x1,3x3)\n        x=self.Conv1x1(inputs)\n        out33=self.Conv3SL1x1(x)\n        \n        #Input via Smart Layer (1x1,5x5)\n        x=self.Conv1x1(inputs)\n        out55=self.Conv5SL1x1(x)\n        \n        #Input via Max Pool\n        x=self.MaxPool(inputs)\n        outMP11=self.ConvMP1x1(x)\n        \n        #concat the outputs\n        output=keras.layers.Concatenate(axis=-1)([out11,out33,out55,outMP11])\n        \n        return output\n    def get_config(self):\n        base_config=super().get_config()\n        return {**base_config,\n                'f11':self.f11,'f311':self.f311,'f333':self.f333,\n                'f511':self.f511,'f555':self.f555,'fMP11':self.fMP11}","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\nDefault2D=partial(keras.layers.Conv2D,kernel_size=3,activation='relu',padding='same')\nMaxPool2D=partial(keras.layers.MaxPool2D,pool_size=2,padding='same')\nmodel_gnet=keras.models.Sequential([\n    Default2D(filters=64,kernel_size=7,input_shape=[28,28,1]),\n    MaxPool2D(),\n    Default2D(filters=32,kernel_size=1),\n    Default2D(filters=128),\n    MaxPool2D(),\n    Inseption2D(f11=32,f311=16,f333=64,f511=16,f555=32,fMP11=16),\n    Inseption2D(f11=64,f311=32,f333=96,f511=32,f555=64,fMP11=32),\n    MaxPool2D(),\n    Inseption2D(f11=96,f311=64,f333=108,f511=64,f555=96,fMP11=64),\n    Inseption2D(f11=108,f311=96,f333=128,f511=64,f555=108,fMP11=64),\n    MaxPool2D(),\n    keras.layers.Flatten(),\n    keras.layers.Dense(90,activation='relu'),\n    keras.layers.Dense(45,activation='relu'),\n    keras.layers.Dense(10,activation='softmax')\n])","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gnet.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_4 (Conv2D)            (None, 28, 28, 64)        3200      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 14, 14, 32)        2080      \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 14, 14, 128)       36992     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\ninseption2d (Inseption2D)    (None, 7, 7, 80)          7248      \n_________________________________________________________________\ninseption2d_1 (Inseption2D)  (None, 7, 7, 160)         11936     \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 4, 4, 160)         0         \n_________________________________________________________________\ninseption2d_2 (Inseption2D)  (None, 4, 4, 288)         38176     \n_________________________________________________________________\ninseption2d_3 (Inseption2D)  (None, 4, 4, 332)         67148     \n_________________________________________________________________\nmax_pooling2d_11 (MaxPooling (None, 2, 2, 332)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1328)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 90)                119610    \n_________________________________________________________________\ndense_4 (Dense)              (None, 45)                4095      \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                460       \n=================================================================\nTotal params: 290,945\nTrainable params: 290,945\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gnet.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='nadam')\nhistory_gnet=model_gnet.fit(Xtrainpp,ytrain,epochs=20,validation_data=(Xvalpp,yval),callbacks=my_callbacks)","execution_count":31,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n827/827 [==============================] - 12s 15ms/step - loss: 0.3867 - accuracy: 0.8723 - val_loss: 0.1443 - val_accuracy: 0.9553\nEpoch 2/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.1018 - accuracy: 0.9690 - val_loss: 0.1268 - val_accuracy: 0.9617\nEpoch 3/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.0788 - accuracy: 0.9766 - val_loss: 0.0855 - val_accuracy: 0.9745\nEpoch 4/20\n827/827 [==============================] - 13s 15ms/step - loss: 0.0645 - accuracy: 0.9794 - val_loss: 0.0783 - val_accuracy: 0.9773\nEpoch 5/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 0.0684 - val_accuracy: 0.9793\nEpoch 6/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.0491 - accuracy: 0.9844 - val_loss: 0.0688 - val_accuracy: 0.9799\nEpoch 7/20\n827/827 [==============================] - 11s 14ms/step - loss: 0.0471 - accuracy: 0.9845 - val_loss: 0.0498 - val_accuracy: 0.9857\nEpoch 8/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.0393 - accuracy: 0.9871 - val_loss: 0.0408 - val_accuracy: 0.9869\nEpoch 9/20\n827/827 [==============================] - 13s 15ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.0772 - val_accuracy: 0.9793\nEpoch 10/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.0694 - val_accuracy: 0.9801\nEpoch 11/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.0328 - accuracy: 0.9901 - val_loss: 0.0501 - val_accuracy: 0.9848\nEpoch 12/20\n827/827 [==============================] - 11s 14ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0411 - val_accuracy: 0.9894\nEpoch 13/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0378 - val_accuracy: 0.9905\nEpoch 14/20\n827/827 [==============================] - 13s 15ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0396 - val_accuracy: 0.9905\nEpoch 15/20\n827/827 [==============================] - 12s 14ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0649 - val_accuracy: 0.9835\nEpoch 16/20\n827/827 [==============================] - 12s 15ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0471 - val_accuracy: 0.9883\nEpoch 17/20\n827/827 [==============================] - 11s 14ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0393 - val_accuracy: 0.9906\nEpoch 18/20\n827/827 [==============================] - 11s 14ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0422 - val_accuracy: 0.9913\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gnet.evaluate(Xtestpp,ytest)","execution_count":32,"outputs":[{"output_type":"stream","text":"92/92 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9881\n","name":"stdout"},{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"[0.06036795303225517, 0.988095223903656]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_gnet.save('mnist_cnn_inseption_988_005.h5') #98.84%  0.05%","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Residual Module (Type-> ResNet)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResidualBlock(keras.layers.Layer):\n    def __init__(self,filters,strides=1,activation='relu',**kwargs):\n        super().__init__(**kwargs)\n        self.filters=filters\n        self.strides=strides\n        self.activation=keras.activations.get(activation)\n        self.main_layers=[\n            keras.layers.Conv2D(filters,2,strides=strides,padding='same',use_bias=False),\n            keras.layers.BatchNormalization(),\n            self.activation,\n            keras.layers.Conv2D(filters,2,strides=1,padding='same',use_bias=False),\n            keras.layers.BatchNormalization()\n        ]\n        self.skip_layers=[]\n        if strides>1:\n            self.skip_layers=[\n                keras.layers.Conv2D(filters,1,strides=strides,padding='same',use_bias=False),\n                keras.layers.BatchNormalization()\n            ]\n    def call(self,inputs):\n        Z=inputs\n        for layer in self.main_layers:\n            Z=layer(Z)\n        skip_Z=inputs\n        for layer in self.skip_layers:\n            skip_Z=layer(skip_Z)\n        return self.activation(Z+skip_Z)\n    \n    def get_config(self):\n        base_config=super().get_config()\n        return {**base_config,\"filters\":self.filters,\"strides\":self.strides,\"activation\":keras.activations.serialize(self.activation)}","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\nDefault2D=partial(keras.layers.Conv2D,kernel_size=3,activation='relu',padding='same')\nMaxPool2D=partial(keras.layers.MaxPool2D,pool_size=2,padding='same')\nmodel_rnet=keras.models.Sequential([\n    Default2D(filters=32,kernel_size=5,input_shape=[28,28,1]),\n    MaxPool2D(),\n    ResidualBlock(filters=64,strides=2),\n    ResidualBlock(filters=64),\n    ResidualBlock(filters=128,strides=2),\n    ResidualBlock(filters=128),\n    MaxPool2D(),\n    keras.layers.Flatten(),\n    keras.layers.Dense(50,activation='relu'),\n    keras.layers.Dense(25,activation='relu'),\n    keras.layers.Dense(10,activation='softmax')\n])","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rnet.summary()","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_31 (Conv2D)           (None, 28, 28, 32)        832       \n_________________________________________________________________\nmax_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n_________________________________________________________________\nresidual_block (ResidualBloc (None, 7, 7, 64)          27392     \n_________________________________________________________________\nresidual_block_1 (ResidualBl (None, 7, 7, 64)          33280     \n_________________________________________________________________\nresidual_block_2 (ResidualBl (None, 4, 4, 128)         108032    \n_________________________________________________________________\nresidual_block_3 (ResidualBl (None, 4, 4, 128)         132096    \n_________________________________________________________________\nmax_pooling2d_13 (MaxPooling (None, 2, 2, 128)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 512)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 50)                25650     \n_________________________________________________________________\ndense_7 (Dense)              (None, 25)                1275      \n_________________________________________________________________\ndense_8 (Dense)              (None, 10)                260       \n=================================================================\nTotal params: 328,817\nTrainable params: 326,897\nNon-trainable params: 1,920\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rnet.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='nadam')\nhistory_rnet=model_rnet.fit(Xtrainpp,ytrain,epochs=20,validation_data=(Xvalpp,yval),callbacks=my_callbacks)","execution_count":15,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n827/827 [==============================] - 10s 12ms/step - loss: 0.2255 - accuracy: 0.9297 - val_loss: 0.1151 - val_accuracy: 0.9656\nEpoch 2/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0756 - accuracy: 0.9766 - val_loss: 0.0981 - val_accuracy: 0.9723\nEpoch 3/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0532 - accuracy: 0.9841 - val_loss: 0.0647 - val_accuracy: 0.9807\nEpoch 4/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0438 - accuracy: 0.9862 - val_loss: 0.0875 - val_accuracy: 0.9756\nEpoch 5/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0349 - accuracy: 0.9896 - val_loss: 0.0840 - val_accuracy: 0.9760\nEpoch 6/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.0723 - val_accuracy: 0.9825\nEpoch 7/20\n827/827 [==============================] - 10s 12ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0502 - val_accuracy: 0.9860\nEpoch 8/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0480 - val_accuracy: 0.9871\nEpoch 9/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0671 - val_accuracy: 0.9837\nEpoch 10/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0542 - val_accuracy: 0.9857\nEpoch 11/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0450 - val_accuracy: 0.9883\nEpoch 12/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0410 - val_accuracy: 0.9894\nEpoch 13/20\n827/827 [==============================] - 10s 12ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0465 - val_accuracy: 0.9883\nEpoch 14/20\n827/827 [==============================] - 10s 12ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0486 - val_accuracy: 0.9880\nEpoch 15/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0653 - val_accuracy: 0.9841\nEpoch 16/20\n827/827 [==============================] - 9s 11ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0366 - val_accuracy: 0.9916\nEpoch 17/20\n827/827 [==============================] - 9s 11ms/step - loss: 7.2560e-04 - accuracy: 0.9999 - val_loss: 0.0419 - val_accuracy: 0.9913\nEpoch 18/20\n827/827 [==============================] - 9s 11ms/step - loss: 3.7339e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9911\nEpoch 19/20\n827/827 [==============================] - 9s 11ms/step - loss: 7.9790e-04 - accuracy: 0.9998 - val_loss: 0.0395 - val_accuracy: 0.9917\nEpoch 20/20\n827/827 [==============================] - 10s 12ms/step - loss: 1.4431e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9918\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rnet.evaluate(Xtestpp,ytest)","execution_count":16,"outputs":[{"output_type":"stream","text":"92/92 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9918\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"[0.04960530251264572, 0.9918367266654968]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rnet.save('mnist_cnn_residual_99_003.h5') #99% 0.03%","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to Submit Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred=your_model_name.predict_classes(your_prepared_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ImageId=pd.Series(range(1,28001))\nLabel=pd.Series(ypred)\nsol=pd.concat([ImageId, Label],axis=1)\nsol=sol.rename(columns={0: \"ImageId\", 1: \"Label\"})\nsol.to_csv('mnist_via_vggnet_sol.csv',index=False)","execution_count":42,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple CNN with depth Pooling (Not Yet Supported By TF)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n\nclass DepthMaxPool(keras.layers.Layer):\n    def __init__(self, pool_size, strides=None, padding=\"VALID\", **kwargs):\n        super().__init__(**kwargs)\n        if strides is None:\n            strides = pool_size\n        self.pool_size = pool_size\n        self.strides = strides\n        self.padding = padding\n    def call(self, inputs):\n        return tf.nn.max_pool(inputs,\n                              ksize=(1, 1, 1, self.pool_size),\n                              strides=(1, 1, 1, self.pool_size),\n                              padding=self.padding)\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n\nfrom functools import partial\n\nDefault2D=partial(keras.layers.Conv2D,kernel_size=3,activation='relu',padding='SAME')\nMaxPool2D=partial(keras.layers.MaxPooling2D,pool_size=2)\nmodel=keras.models.Sequential([\n    Default2D(filters=90,kernel_size=7,input_shape=[28,28,1]),\n    MaxPool2D(),\n    Default2D(filters=180),\n    MaxPool2D(),\n    Default2D(filters=256),\n    DepthMaxPool(16),\n    Default2D(filters=360),\n    MaxPool2D(),\n    keras.layers.Flatten(),\n    keras.layers.Dense(90,activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(45,activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(10,activation='softmax')\n])\n\n\nmodel.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='nadam')\nhistory=model.fit(Xtrainpp,ytrain,epochs=5,validation_data=(Xvalpp,yval))\nscore=model.evaluate(Xtestpp,ytest)\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* If u reached here, a tip if u need the models they are in output section"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}